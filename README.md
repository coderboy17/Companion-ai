ğŸ‘“ AI Seeing Companion - Voice-Controlled Smart Glasses Assistant

A voice-controlled AI companion designed for blind and visually impaired users, acting as digital eyes using computer vision, OCR, and speech recognition.
The assistant works fully through voice commands and provides audio feedback.

It supports:

Object detection (using YOLOv4-Tiny)

Text recognition (OCR with EasyOCR)

Voice-guided camera setup (webcam or ESP32-CAM smart glasses)

Real-time scene description

Person detection

Smart voice-based settings and help

ğŸš€ Features

ğŸ¤ Voice-First Interface â€“ Fully operable via voice commands

ğŸ‘ï¸ Scene Description â€“ Describes objects and surroundings

ğŸ“– Text Reader â€“ Reads aloud any visible text

ğŸ§ Person Finder â€“ Detects people in the environment

ğŸ” Object Finder â€“ Locates specific objects on request

âš™ï¸ Voice Settings â€“ Change speech speed and announcement frequency

ğŸ”„ Continuous Monitoring â€“ Alerts for new important objects (e.g., people, cars)

ğŸ“¡ ESP32-CAM Integration â€“ Supports smart glasses camera input

ğŸ“¦ Requirements

Make sure you have the following installed:

Python 3.7+

Required libraries (install via pip):

pip install opencv-python numpy easyocr pyttsx3 SpeechRecognition pillow requests


YOLOv4-tiny model files (downloaded automatically at runtime if missing):

yolov4-tiny.cfg

yolov4-tiny.weights

coco.names

ğŸ–¥ï¸ Usage
1. Clone the Repository
git clone https://github.com/your-username/ai-seeing-companion.git
cd ai-seeing-companion

2. Run the Assistant
python ai_companion.py

3. Voice Setup Wizard

When launched, the assistant will guide you via speech:

Say "webcam" â†’ to use computer/phone camera

Say "glasses" â†’ to use ESP32-CAM smart glasses (youâ€™ll provide IP address by voice)

ğŸ™ï¸ Voice Commands

Here are the main commands you can say anytime:

Command	Action
"describe" / "what do you see"	Describes the current scene
"read text"	Reads text from the camera feed
"find person"	Detects nearby people
"find [object]"	Looks for a specific object (e.g., "find chair")
"settings"	Opens voice settings menu
"pause"	Pauses automatic announcements
"resume"	Resumes automatic announcements
"help"	Lists available commands
"exit" / "goodbye"	Shuts down the assistant
ğŸ“± ESP32-CAM Smart Glasses

If using ESP32 smart glasses:

Connect ESP32-CAM to WiFi

Note the IP address (e.g., 192.168.1.100)

During setup, say: "glasses" â†’ then speak the IP address in natural form (e.g., "one nine two dot one six eight dot one dot one zero zero")

âš ï¸ Notes

Ensure microphone and camera permissions are granted

Works on Windows, Linux, macOS, and Android (Termux)

Uses Google Speech Recognition API (requires internet connection)

YOLOv4-tiny is optimized for real-time detection on low-resource devices

ğŸ› ï¸ Future Improvements

Add offline speech recognition (Vosk or Whisper)

Support for multi-language OCR

Expand object detection models for better accuracy

Mobile-friendly packaging (APK / standalone app)

ğŸ‘¤ Author

Developed as an AI accessibility project for visually impaired assistance
